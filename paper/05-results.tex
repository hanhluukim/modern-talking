\section{Results}\label{results}

\todo{Discuss results.}

\subsection{Automatic Evaluation}
\input{figures/table-results.tex}
In Table~\ref{table-results}, we report mean average precision, precision, recall, and F1 scores of the match label for the training, validation, and test set of the ArgKP dataset. We include scores from the term-overlap baseline model as well as for the fine-tuned \BertBase and \RobertaBase models.
We assess these four metrices to allow for automated and unbiased evaluation of our models.

\todo{Shortly describe metric.}
\todo{Report results for \Roberta model and baseline.}

\subsection{Manual Error Analysis}

\todo{Find example errors from our classifier. How can we improve?}
