We contribute to the ArgMining~2021 shared task on Quantitative Summarization and Key Point Analysis with two approaches for argument key point matching.
For key point matching the task is to decide if a short key point matches the content of an argument with the same topic and stance towards the topic.
We approach this task in two ways:
First, we develop a simple rule-based baseline matcher by computing term overlap after removing stop words, stemming, and adding synonyms/antonyms.
Second, we fine-tune pretrained \Bert and \Roberta language models as a regression classifier for only a single epoch.
We manually examine errors of our proposed matcher models and find that long arguments and arguments without any matching key point in the training data are harder to classify.
Our fine-tuned \RobertaBase model achieves a mean average precision score of~0.913, the best score for strict labels of all participating teams.
