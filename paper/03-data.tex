\section{Data}\label{data}

The dataset used in this shared task is the IBM Debater(R) - ArgKP v1 \cite{Bar-HaimEFKLS2020} which consists of over 
24.000 argument and key point pairs labeled as matching/non-matching.
They all belong to one of 28 controversial topics ranging from "Assisted suicide should be a criminal offence." to 
"We should abandon marriage." therefore drawing a clear line between supporting and non-supporting key points.

The section used for training has over 5500 arguments belonging to over 200 key points with 24 topics. This leaves the 
dev dataset with over 900 arguments and 36 key points for 4 topics.

\subsection{Characteristics}

\todo{Report data characteristics from exploratory data analysis.}
When analyzing the data, we realize that matched and unmatched key points of a given argument contain a certain proportion of the same words. Many of these words belong to the set of stop words. These uninformative, non-decisive words can complicate the decision process between the matched and unmatched keypoint. For this reason, we remove stop words from our data during pre-processing. Furthermore, the important words from the argument are repeated with different tenses and parts of speech in key points, for example: \textit{legalize, legalized, legalizing, legal} or \textit{marriages, marriage}. Because these words were used again, they can play a role in classification. To achieve an unambiguous spelling, such words are normalized with a stemming method in our approach. Moreover, this conversion to the word root reduces the size of the vocabulary or the dimensions of the text input. With a low number of dimensions, the assumption of independence of individual features in general machine learning algorithms is violated with a low probability. 

In the next examples, we can see that the use of synonyms or semantically similar words can be a cause for misclassification. The key point \textit{Being a performer harms the child's education} can be matched with the argument \textit{child actors can be overworked and they can miss out on their education} with a high probability. The two sentences were written on the topic of children actors and their education, although the word \textit{actors} is not explicitly used in the key point. We know that \textit{performer} and \textit{actors} are semantically relevant and \textit{performer} and \textit{actor} both perform. In another example, the argument \textit{capital punishment breaks the human rights of the individuals being punished} and the key point \textit{State-sanctioned killing is principally wrong} were expressed completely differently. The important words \textit{capital punishment}, \textit{state-sanctioned killing} show us that the two sentences were written at least about the same topic. This poses a challenge for us to design our approach in such a way that it knows the different written words with the same meaning. A simple method we use is to apply the well-known lexical database WortNet for the English language.

It is still recognized that context understanding can be a challenge for the task. For this topic from test dataset:
\textit{We should abandon the use of school uniform}, there is an argument: \textit{it is not fair to not allow children to express their personality through dress as long as it is appropriate}. The posible matched key point is \textit{School uniform is harming the student's self-expression}. We can first see that the argument and the gaven key point have little in common: \textit{express, expression}. To predict if the key point is aligned with the argument, we need to compare their meanings. To better deal with the problem of semantic meaning, we use two well-known language models in our second approach, which we describe in more detail in the next chapter Approach.