\section{Related Work} 

    \subsection{Argument Clustering}

    \subsection{Key Point Analysis}
        Given the first track of the shared task analyzing key points is crucial. In their work \cite{Bar-HaimEFKLS2020} 
        Bar-Haim et al. proposed an approach for summarising large argument collections to small sets of key points. Thus
        covering a sufficient amount of all arguments. They showed that domain experts can very quickly
        create pro and con key points, which are a able to capture the gist of the arguments on the given topic. All this
        without being exposed to the arguments themself. Furthermore they developed the large-scale dataset ArgKP
        which is the foundation of this shared task. 
        In a later work \cite{Bar-HaimKEFLS2020} Bar-Haim et al. constructed an automatic method for key point 
        extraction which can compete with key points created by human domain experts. The method consists of two aspects. 
        Assuming that the key points can be found among the given comments 
        they first select short, high quality comments as key point candidates an then select the candidate with the highest
        data coverage. Using the HuggingFace transformer framework they fine-tuned four different models from which 
        ALBERT \cite{lan2019albert} had the best F1 score with $0.809$ but RoBERTa \cite{liu2019roberta} (F1 score of 
        $0.773$) was choosen for key point extraction since it had a 6 times faster inference time. 
        In the paper \cite{egan2016summarising}, Egan et al. proposed a summarising for informal arguments such as they
        occure in online political debates. By extracting verbs and their syntactic arguments they retrieve points which
        can make key content accessible. By grouping these points they propose to create discussion summaries.

    \subsection{Stance Classification}
