\documentclass[english,handout]{mlutalk}

\title{%
  Modern Talking: Key-Point Analysis \\
  using Modern Language Understanding
}
\subtitle{Natural Language Processing, Summer Semester 2021}
\author{Max Henze \and Hanh Luu \and Jan Heinrich Reimer}
\institute{Martin Luther University Halle-Wittenberg}
\date{June 29, 2021}
\titlegraphic{\includegraphics[width=3cm]{figures/mlu-halle}}

\addbibresource{../literature/literature.bib}

\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{listings}
\usepackage{xspace}
\usepackage{biblatex}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{graphics,graphicx}

\newcommand{\ArgKP}{\mbox{ArgKP}\xspace}
\newcommand{\ArgQ}{\mbox{IBM-ArgQ-Rank-30kArgs}\xspace}
\newcommand{\BiLSTM}{\mbox{BiLSTM}\xspace}
\newcommand{\Bert}{\textsc{Bert}\xspace}
\newcommand{\BertBase}{\Bert-Base\xspace}
\newcommand{\BertLarge}{\Bert-Large\xspace}
\newcommand{\Roberta}{\mbox{Ro\textsc{Bert}a}\xspace}
\newcommand{\RobertaBase}{\Roberta-Base\xspace}
\newcommand{\TF}{\mbox{TF}\xspace}
\newcommand{\TFIDF}{\mbox{TF/IDF}\xspace}
\newcommand{\todocite}{{\smaller\color{red}[CITE]}\xspace}
\newcommand{\todo}[1]{{\smaller\color{red}[#1]}}

\tikzset{%
  every neuron/.style={
    circle,
    draw,
    minimum size=1cm
  },
  layer/.style= {
    rectangle,
    draw,
    minimum size = 1cm
  }
}

\begin{document}

\titleframe

\begin{frame}{Initial Ideas}
  
  \begin{itemize}
    \item Rule-based baseline
    \item Improve upon the baseline with Machine Learning
    \begin{itemize}
      \item Regression, SVC~\todocite
      \item Ensemble
      \item Deep Neural Networks, e.g., \BiLSTM~\todocite with GloVe embeddings~\todocite, \Bert~\todocite
    \end{itemize}
    \item Variations of the above \(\to\) Hyper-parameter tuning
  \end{itemize}
  
  \begin{block}{What did not work?}
    Some of the brainstormed ideas did not improve upon the baseline:
    \begin{itemize}
      \item Regression, SVC
      \item Ensemble
      \item \BiLSTM
    \end{itemize}
  \end{block}
  
  \begin{block}{What did work?}
    \begin{itemize}
      \item \Bert
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}[allowframebreaks]{Term Overlap}
  
  \begin{itemize}
    \item Rule-based approach with no training
    \item Features: (preprocessed) terms
    \item Preprocessing:
    \begin{itemize}
      \item Stemming \(\leadsto\) generalization
      \item Stop words \(\leadsto\) less noise/confusion \\ modified without \query{not}
      \item Synonyms, antonyms \(\leadsto\) generalization
    \end{itemize}
    \item Compute similarity based on Jaccard similarity coefficient~\todocite, i.e., proportion of terms that appear in argument and key point
    \item Good improvement with preprocessing: up to 12~pp \todo{don't abbreviate}
  \end{itemize}
  
  \begin{example}[Preprocessing]
    \smaller
    Homeschooling a child denies them valuable lifeskills, particularly interaction with their own age group and all experiences stemming from this. \\
    \(\to\) homeschool child deni valuabl lifeskil particular interact age group experi stem
  \end{example}

  \framebreak
  
  \begin{block}{Technology}
      \begin{itemize}
        \item NTLK~\todocite for tokenization, stemming,  and stop word list
        \item WordNet~\todocite (via NLTK) for synonyms and antonyms
      \end{itemize}
  \end{block}

  \begin{block}{Intuition}
    \begin{itemize}
      \item Many arguments contain the same words as matching key points
      \item Key points summarize arguments
      \item Stemming/synonyms/antonyms increase overlap
    \end{itemize}

    \begin{example}
      \smaller
      \begin{tabular}{lp{0.7\textwidth}}
        Argument: & People reach their limit when it comes to their quality of life and should be able to end their {\color{blue} suffering}. This can be done with little or no {\color{blue} suffering} by {\color{orange} assistance} and the person is able to say good bye. \\
        Key Point: & {\color{orange} Assisted} suicide reduces {\color{blue} suffering}.
      \end{tabular}
    \end{example}
  \end{block}

\end{frame}

\begin{frame}{Regression, SVC}
  
  \framesubtitle{What did not work?}
  
  \begin{itemize}
    \item Features: bag-of-words and/or \TFIDF for selected parts-of-speech
    \item Regression \todo{what type?}, Support Vector Classifier
    \item Ensemble of Regression + SVC
  \end{itemize}
  
  \begin{block}{Technology}
      \begin{itemize}
        \item NTLK~\todocite for tokenization \todo{didn't we?}, stemming,  and stop word list
        \item spaCy~\todocite for part-of-speech tagging
        \item Scikit-Learn~\todocite for bag-of-words and \TFIDF
        \item Scikit-Learn~\todocite for regression and SVC implementation
      \end{itemize}
  \end{block}

\end{frame}

\begin{frame}{Regression, SVC}

  \framesubtitle{Why did it not work?}

  \begin{itemize}
    \item Too much features~(\( > 4000 \)) for Regression
    \item SVC better results, but still worse than baseline
    \item Can't capture context or semantic meaning
  \end{itemize}

  \begin{example}[False Positives]
    \smaller
    \begin{tabular}{ll}
      Argument: & School uniforms violate the right to freedom of expression. \\
      Key Point: & School uniforms are often uncomfortable/sexist. \\
      Prediction: & Match
    \end{tabular}
  \end{example}
  
  \begin{example}[False Negatives]
    \smaller
    \begin{tabular}{ll}
      Argument: & It is not fair to not allow children to express their personality through dress as long as it is appropriate. \\
      Key Point: & School uniform is harming the student's self expression. \\
      Prediction: & No match
    \end{tabular}
  \end{example}

\end{frame}

\begin{frame}[allowframebreaks]{Bidirectional LSTM}
  
  \framesubtitle{What did not work?}
  
  \begin{itemize}
    \item Embed with GloVe~\todocite
    \item Encode argument and key point separately \\ with bidirectional long short-term memory model~(\BiLSTM)
    \item Merge pooled outputs to estimate similarity
  \end{itemize}
  
  \begin{block}{Preprocessing}
      \begin{itemize}
        \item Missing labels in training data
        \begin{description}
          \item[skip] Use only labeled pairs
          \item[strict] Assume no match
          \item[relaxed] Assume match
        \end{description}
        \item Data Augmentation with WordNet~\todocite synonyms and common misspellings
      \end{itemize}
  \end{block}

  \framebreak

  \begin{figure}
    \begin{tikzpicture}[xscale=1.75, yscale=2.5, >=stealth]
      \node[every neuron] (arg) at (0, 1) {Arg.};
      \node[every neuron] (kp) at (0, 0) {KP.};
      \node[layer] (vec) at (1, 0.5) {Vec.};
      \node[layer] (glove) at (2, 0.5) {GloVe};
      \node[layer] (bilstm-arg) at (3, 1) {\BiLSTM};
      \node[layer] (bilstm-kp) at (3, 0) {\BiLSTM};
      \node[every neuron] (merge) at (3, 0.5) {\(-\)};
      \node[layer] (bilstm) at (4, 0.5) {\BiLSTM};
      \node[layer] (dense) at (5, 0.5) {Dense};
      \node at (4.75, 1.1) {\small \BiLSTM+GloVe};
      \draw[draw=blue] (0.5, -0.25) rectangle (5.5, 1.25);
      \draw[->] (arg) -- (vec);
      \draw[->] (kp) -- (vec);
      \draw[->] (vec) -- (glove);
      \draw[->] (glove) -- (bilstm-arg);
      \draw[->] (glove) -- (bilstm-kp);
      \draw[->] (bilstm-arg) -- (merge);
      \draw[->] (bilstm-kp) -- (merge);
      \draw[->] (merge) -- (bilstm);
      \draw[->] (bilstm) -- (dense);
      \draw[->] (dense) -- (6, 0.5);
    \end{tikzpicture}
    \caption{\BiLSTM+GloVe model}
  \end{figure}
  
  \begin{block}{Technology}
      \begin{itemize}
        \item TensorFlow~\todocite and Keras~\todocite for model layers~(e.g., RNN) and tokenization
        \item NLPAug~\todocite for data augmentation
      \end{itemize}
  \end{block}

\end{frame}

\begin{frame}{Bidirectional LSTM}
  \framesubtitle{Why doesn't it work?}

  \begin{itemize}
    \item Complex hyper-parameters
    \item Epochs
    \begin{itemize}
      \item Too few~(1--10) \(\to\) okay on training set but no generalization on dev set
      \item Too much~(10--100) \(\to\) overfiting
    \end{itemize}
    \item Slow learning rate~\(\eta = 0.0001\) does not improve much
    \item Early stopping, dropout layers, and weight decay \(\to\) neglible improvements
    \item Generate new samples~(data augmentation) \(\to\) \textquote{confuses} model
  \end{itemize}

  \begin{block}{Conclusion}
    \BiLSTM model probably to difficult or wrong way of data input.
  \end{block}

\end{frame}

\begin{frame}{\Bert and Transformers}
  \framesubtitle{Used technologies + Preprocessing + Approach + Parameters}

  \begin{itemize}
    \item \todo{How to use \Bert as classifier?}
  \end{itemize}
  
  \begin{block}{Technology}
    \begin{itemize}
      \item Simple Transformers~\todocite for model layers~(e.g., RNN) and tokenization
      \item NLPAug~\todocite for data augmentation
    \end{itemize}
  \end{block}

\end{frame}

\begin{frame}{\Roberta}
  \todo{Differences}

  \begin{block}{Hyper-parameter settings}
    
  \end{block}
\end{frame}

\begin{frame}{Evaluation}
  \framesubtitle{Mean Average Precision}
  \begin{figure}
    \centering
    \caption{Mean average precision of the match label for different approaches and baselines, as computed by the KPA\,2021 Shared Task's evaluation script.}
    \tiny
    \begin{tabular}{lrrrlrrr}
      \toprule
      Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cmidrule{2-4} \cmidrule{6-8}
        & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
      \midrule
      Random 
      & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000 \\
      Term Overlap (no preprocessing)
      & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000 \\
      Term Overlap (with preprocessing)
      & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000 \\
      \midrule
      BiLSTM (GloVe embeddings)
      & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000 \\
      \BertBase
      & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000 \\
      \RobertaBase
      & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000 \\
      \bottomrule
    \end{tabular}
  \end{figure}
\end{frame}

\begin{frame}{Evaluation}
  \framesubtitle{Precision}
  \begin{figure}
    \centering
    \caption{Precision of the match label for different approaches and baselines.}
    \tiny
    \begin{tabular}{lrrrlrrr}
      \toprule
      Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cmidrule{2-4} \cmidrule{6-8}
        & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
      \midrule
      Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \midrule
      BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \bottomrule
    \end{tabular}
  \end{figure}
\end{frame}

\begin{frame}{Evaluation}
  \framesubtitle{Macro Precision}
  \begin{figure}
    \centering
    \caption{Macro precision of both labels for different approaches and baselines.}
    \tiny
    \begin{tabular}{lrrrlrrr}
      \toprule
      Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cmidrule{2-4} \cmidrule{6-8}
        & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
      \midrule
      Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \midrule
      BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \bottomrule
    \end{tabular}
  \end{figure}
\end{frame}

\begin{frame}{Evaluation}
  \framesubtitle{Recall}
  \begin{figure}
    \centering
    \caption{Recall of the match label for different approaches and baselines.}
    \tiny
    \begin{tabular}{lrrrlrrr}
      \toprule
      Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cmidrule{2-4} \cmidrule{6-8}
        & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
      \midrule
      Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \midrule
      BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \bottomrule
    \end{tabular}
  \end{figure}
\end{frame}

\begin{frame}{Evaluation}
  \framesubtitle{Macro Recall}
  \begin{figure}
    \centering
    \caption{Macro recall of both labels for different approaches and baselines.}
    \tiny
    \begin{tabular}{lrrrlrrr}
      \toprule
      Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cmidrule{2-4} \cmidrule{6-8}
        & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
      \midrule
      Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \midrule
      BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \bottomrule
    \end{tabular}
  \end{figure}
\end{frame}

\begin{frame}{Evaluation}
  \framesubtitle{F1-Score}
  \begin{figure}
    \centering
    \caption{F1-Score of the match label for different approaches and baselines.}
    \tiny
    \begin{tabular}{lrrrlrrr}
      \toprule
      Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cmidrule{2-4} \cmidrule{6-8}
        & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
      \midrule
      Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \midrule
      BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \bottomrule
    \end{tabular}
  \end{figure}
\end{frame}

\begin{frame}{Evaluation}
  \framesubtitle{Macro F1-Score}
  \begin{figure}
    \centering
    \caption{Macro F1-score of both labels for different approaches and baselines.}
    \tiny
    \begin{tabular}{lrrrlrrr}
      \toprule
      Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cmidrule{2-4} \cmidrule{6-8}
        & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
      \midrule
      Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \midrule
      BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
      \bottomrule
    \end{tabular}
  \end{figure}
\end{frame}

\appendix
\section{\appendixname}

\bibliographyframe

\end{document}