\documentclass[english,handout]{mlutalk}

\title{Stance Classification for Key-Point Analysis}
% \title{%
%   Modern Talking: Key-Point Analysis \\
%   using Modern Natural Language Processing
% }
\subtitle{Natural Language Processing, Summer Semester 2021}
\author{Max Henze \and Hanh Luu \and Jan Heinrich Reimer}
\institute{Martin Luther University Halle-Wittenberg}
\date{April 20, 2021}
\titlegraphic{\includegraphics[width=3cm]{figures/mlu-halle}}

\addbibresource{../literature/literature.bib}

\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{listings}
\usepackage{xspace}
\usepackage{biblatex}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{graphics,graphicx}

\newcommand{\Bert}{\textsc{Bert}\xspace}
\newcommand{\ArgKP}{\mbox{ArgKP}\xspace}
\newcommand{\ArgQ}{\mbox{IBM-ArgQ-Rank-30kArgs}\xspace}
\newcommand{\BiLSTM}{\mbox{BiLSTM}\xspace}
\newcommand{\BertBase}{\textsc{Bert}-Base\xspace}
\newcommand{\BertLarge}{\textsc{Bert}-Large\xspace}
\newcommand{\TF}{\mbox{TF}\xspace}
\newcommand{\TFIDF}{\mbox{TF/IDF}\xspace}

\tikzset{%
    every neuron/.style={
      circle,
      draw,
      minimum size=1cm
    },
    neuron missing/.style={
      draw=none, 
      scale=4,
      text height=0.333cm,
      execute at begin node=\color{black}$\vdots$
    },
    layer/.style= {
      rectangle,
      draw,
      minimum size = 1cm
    }
  }

\begin{document}

\titleframe

\begin{frame}
  \frametitle{Brainstorming}

  \begin{itemize}
    \item A lot of ideas came to our minds
    \begin{itemize}
      \item Rulebased
      \item Machine Learning
      \item BERT
      \item All Kinds of Variations of these
    \end{itemize}   
  \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{What did not work ?}
  \framesubtitle{Regression, SVC, Ensemble}
    \begin{itemize}
      \item All approaches performed mediocre
      \item Machine Learning methods: Regression, SVC, Ensemble(Regression, SVC)
      \item Feature Extraction methods: Bag of Words, TFIDF
      \item Used technologies
      		\begin{itemize}
    		\item Feature extraction
    		\begin{itemize}
    			\item NTLK: Stemming, Stopwords
    			\item spaCy: Part of Speech
    			\item sklearn: CountVectorizer, TFIDFVectorizer
    		\end{itemize}
    		\item Learning methods from sklearn
    	\end{itemize}
    \end{itemize}
  

\end{frame}

\begin{frame}
  \frametitle{What did not work ? cont. }
  \framesubtitle{Feature Extraction and Machine Learning methods}
    
    	\begin{itemize}
      \item high-dimensional data (> 4000 for basis feature extraction)
      	\begin{itemize}
      		\item Regression: not robust for high-dimensional data
      		\item SVC: better results then regression
      	\end{itemize}
	\end{itemize}
	
    \begin{itemize}
      \item problematic with semantic meaning
      \item prediction based on the existence of words
	\end{itemize}
   
    \begin{example}
      \textbf{Argument:} \textit{School uniforms violate the right to freedom of expression.}\\
      \textbf{Key Point:} \textit{School uniforms are often uncomfortable/sexist}\\
      \textbf{Prediction:} Matching
    \end{example}
    
     \begin{example}
      \textbf{Argument:} \textit{it is not fair to not allow children to express their personality through dress as long as it is appropriate.}\\
      \textbf{Key Point:} \textit{School uniform is harming the student's self expression.}\\
      \textbf{Prediction:} No Matching
    \end{example}

\end{frame}

\begin{frame}
  \frametitle{What did work ?}
  \framesubtitle{Term Overlap}
    
    \begin{itemize}
      \item Term Overlap in different variations
      \begin{itemize}
        \item Without preprocessing already high relaxed mAP
        \item Using stemming, stop words etc. increased both scores by up to 12 pp 
      \end{itemize} 
      \item BiLSTM with GloVe embeddings
      \item Pretrained BERT model
    \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{Term Overlap}
  \framesubtitle{Used Technologies + Preprocessing}
    \begin{itemize}
      \item NLTK 
        \begin{itemize}
          \item Stemming
          \begin{itemize}
            \item Removing unnecessary Pre - and Suffixes for Generalization
          \end{itemize}
          \item Tokenization
          \begin{itemize}
            \item Necessary for Vounting Overlapping Words
          \end{itemize}
          \item Stopword Removal (with Standard and Modified Stopword List)
          \begin{itemize}
            \item Reduces the Load and removes Clutter from Sentences
            \item Makes Key Words more prominent
          \end{itemize}
          
          \begin{example}
            \textbf{Arg:} \textit{homeschooling a child denies them valuable lifeskills, particularly interaction with their own age group and all experiences stemming from this.}\\
            \textbf{New Arg:} \textit{homeschool child deni valuabl lifeskil , particular interact age group experi stem .}
          \end{example}

          \item Synonyms and Antonyms for Overlap Calculation
          \begin{itemize}
            \item Child $\rightarrow$ Kid, Youngster, nestling etc.
          \end{itemize}
        \end{itemize}
    \end{itemize}
    
\end{frame}

\begin{frame}
  \frametitle{Term Overlap cont.}
  \framesubtitle{Why is Performance so good overall?}
    %TODO Cite paper or lecture which inspired to use models
    
    \begin{itemize}
      \item A lot of arguments contain the same words as the key points
        \begin{itemize}
          \item Fits our Intuition that Key Points summarize Arguments
          \item Stemming and Synonyms/Antonyms make it much more likely for Words to overlap
        \end{itemize}
    \end{itemize}

    \begin{example}
      \textbf{Argument:} \textit{people reach their limit when it comes to their quality of life and should be able to end their suffering. this can be done with little or no suffering by assistance and the person is able to say good bye.}\\
      \textbf{Key Point:} \textit{Assisted suicide reduces suffering}
    \end{example}

\end{frame}

\begin{frame}
  \frametitle{Term Overlap cont.}
  \framesubtitle{Features}
    
    
\end{frame}

\begin{frame}
  \frametitle{BiLSTM}
  \framesubtitle{Used technologies + Preprocessing}

  \begin{itemize}
    \item Tensorflow with Keras brings all RNN Technology
    \item NLPAUG for Augmenting Words
    
    \item Created different metrics how to deal with unlabeled pairs
      \begin{itemize}
        \item \textbf{skip} : use labeled pairs only
        \item \textbf{strict} : missing labels are seen as: "No Match"
        \item \textbf{relaxed} : missing labels are seen as: "Match"
      \end{itemize}
  \end{itemize}

  

\end{frame}


% \begin{frame}
%   \frametitle{BiLSTM}
%   \framesubtitle{}
%     %TODO cite paper which inspired to use blstm
%   \begin{figure}
%     \begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth, scale = 1]
%       \node [every neuron] (arg) at (0,2.5) {arg};
%       \node [every neuron] (kp) at (0,1.5) {kp};
  
%       \node [layer] (wp) at (1.5, 2) {Word Piece};
%       \node [layer] (be) at (3.5, 2) {BERT Embedding};
  
%       \node [layer] (bm1) at (5.5, 3.5) {BiLSTM};
%       \node [layer] (bm2) at (5.5, 0.5) {BiLSTM};
  
%       \node [layer] (con) at (5.5, 2) {+};
%       \node [layer] (den) at (7, 2) {Dense};

%       \node [] (des) at (1.3,3.9) {\small BERT + BiLSTM};
  
%       \draw [->] (arg) -- (wp);
%       \draw [->] (kp) -- (wp);

%       \draw [->] (wp.20) -- (be.166);
%       \draw [->] (wp.340) -- (be.194);

%       \draw [->] (be.15) -- (bm1.180);
%       \draw [->] (be.345) -- (bm2.180);

%       \draw [->] (bm1.270) -- (con.90);
%       \draw [->] (bm2.90) -- (con.270);

%       \draw [->] (con) -- (den);

%       \draw [->] (den) -- (7.8 ,2);

%       \draw[draw=red] (7.5,0) rectangle (0.5,4);
%     \end{tikzpicture}
%   \end{figure}
% \end{frame}

\begin{frame}
  \frametitle{BiLSTM}
  \framesubtitle{Approach}
    %TODO cite paper which inspired to use blstm
  \begin{figure}
    \begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth, scale = 1]
      \node [every neuron] (arg) at (0,2.5) {arg};
      \node [every neuron] (kp) at (0,1.5) {kp};
  
      \node [layer] (wp) at (1.5, 2) {Vectorize};
      \node [layer] (be) at (3.5, 2) {GloVe Embedding};
  
      \node [layer] (bm1) at (5.5, 3.5) {BiLSTM};
      \node [layer] (bm2) at (5.5, 0.5) {BiLSTM};
  
      \node [layer] (con) at (5.5, 2) {+ BiLSTM};
      \node [layer] (den) at (7, 2) {Dense};

      \node [] (des) at (1.3,3.9) {\small GloVe + BiLSTM};
  
      \draw [->] (arg) -- (wp);
      \draw [->] (kp) -- (wp);

      \draw [->] (wp.20) -- (be.166);
      \draw [->] (wp.340) -- (be.194);

      \draw [->] (be.15) -- (bm1.180);
      \draw [->] (be.345) -- (bm2.180);

      \draw [->] (bm1.270) -- (con.90);
      \draw [->] (bm2.90) -- (con.270);

      \draw [->] (con) -- (den);

      \draw [->] (den) -- (7.8 ,2);

      \draw[draw=red] (7.5,0) rectangle (0.5,4);
    \end{tikzpicture}
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{BiLSTM}
  \framesubtitle{Predictions on why did it not work ?}
    
  Tested a lot of different parameter settings:
  \begin{itemize}
    \item Epochs
    \begin{itemize}
      \item Few $(1-10)$ resulted in good scores on training set but mediocre on dev set
      \item A lot $(10-100)$ resulted in decreasing \texttt{val\_acc} $\rightarrow$ Overfiting
      \item Used EarlyStopping, Dropout and Weight Decay against it
    \end{itemize}
  \end{itemize}
  Maybe we were learning to quickly or our data was not enough:
  \begin{itemize}
    \item Learning Rate 
    \begin{itemize}
      \item Set to $0.0001$ showed no significant improvement
    \end{itemize}
    \item Text Augmentation
    \begin{itemize}
      \item Creating new data from old for better generalization
      \item Yielded no improvement
    \end{itemize}
  \end{itemize}

  At this point: model probably to difficult or wrong way of data input

\end{frame}

\begin{frame}
  \frametitle{Transformers}
  \framesubtitle{Used technologies + Preprocessing}
  

\end{frame}

\begin{frame}
  \frametitle{Transformers}
  \framesubtitle{Approach + Parameters}
  

\end{frame}

\begin{frame}
  \frametitle{BERT}
  \framesubtitle{Used technologies + Preprocessing}
  

\end{frame}

\begin{frame}
  \frametitle{BERT}
  \framesubtitle{Approach + Parameters}
    
  

\end{frame}

% EVALUATION OF BASELINE AND APPROACHES

\begin{frame}
  \frametitle{Evaluation}
  \begin{figure}
    \centering
    \scalebox{0.70}{
      \begin{tabular}{lrrrlrrr}
          \multicolumn{8}{c}{\textbf{\Large Mean Average Precision}}\\
          \hspace{1em}\\
        \toprule
          Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cline{2-4} \cline{6-8}
          & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
        \midrule
          Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \midrule
          BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \bottomrule
      \end{tabular}
    }
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Evaluation cont.}
  \begin{figure}
    \centering
    \scalebox{0.70}{
      \begin{tabular}{lrrrlrrr}
          \multicolumn{8}{c}{\textbf{\Large Precision}}\\
          \hspace{1em}\\
        \toprule
          Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cline{2-4} \cline{6-8}
          & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
        \midrule
          Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \midrule
          BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \bottomrule
      \end{tabular}
    }
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Evaluation cont.}
  \begin{figure}
    \centering
    \scalebox{0.70}{
      \begin{tabular}{lrrrlrrr}
          \multicolumn{8}{c}{\textbf{\Large Macro Precision}}\\
          \hspace{1em}\\
        \toprule
          Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cline{2-4} \cline{6-8}
          & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
        \midrule
          Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \midrule
          BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\       
        \bottomrule
      \end{tabular}
    }
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Evaluation cont.}
  \begin{figure}
    \centering
    \scalebox{0.70}{
      \begin{tabular}{lrrrlrrr}
          \multicolumn{8}{c}{\textbf{\Large Recall}}\\
          \hspace{1em}\\
        \toprule
          Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cline{2-4} \cline{6-8}
          & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
        \midrule
          Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \midrule
          BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\       
        \bottomrule
      \end{tabular}
    }
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Evaluation cont.}
  \begin{figure}
    \centering
    \scalebox{0.70}{
      \begin{tabular}{lrrrlrrr}
          \multicolumn{8}{c}{\textbf{\Large Macro Recall}}\\
          \hspace{1em}\\
        \toprule
          Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cline{2-4} \cline{6-8}
          & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
        \midrule
          Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \midrule
          BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\       
        \bottomrule
      \end{tabular}
    }
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Evaluation cont.}
  \begin{figure}
    \centering
    \scalebox{0.70}{
      \begin{tabular}{lrrrlrrr}
          \multicolumn{8}{c}{\textbf{\Large F1-Score}}\\
          \hspace{1em}\\
        \toprule
          Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cline{2-4} \cline{6-8}
          & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
        \midrule
          Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \midrule
          BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \bottomrule
      \end{tabular}
    }
  \end{figure}
\end{frame}

\begin{frame}
  \frametitle{Evaluation cont.}
  \begin{figure}
    \centering
    \scalebox{0.70}{
      \begin{tabular}{lrrrlrrr}
          \multicolumn{8}{c}{\textbf{\Large Macro F1 Score}}\\
          \hspace{1em}\\
        \toprule
          Baselines/Approach & \multicolumn{3}{c}{Training Data} & & \multicolumn{3}{c}{Validation Data}\\ \cline{2-4} \cline{6-8}
          & Strict & Relaxed & Average & & Strict & Relaxed & Average\\
        \midrule
          Match All                           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Match None                          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (no prepro)            & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo)          & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Term Overlap (stem, stowo, syn, ant)& 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
        \midrule
          BiLSTM (GloVe embeddings)           & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Base (skip)                    & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          BERT-Large (skip)                   & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          RoBERTa-Base (skip)                 & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          DistilBERT-Base (skip)              & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\
          Transformers                        & 00000 & 00000 & 00000 & & 00000 & 00000 & 00000\\     
        \bottomrule
      \end{tabular}
    }
  \end{figure}
\end{frame}

% \begin{frame}
%   \frametitle{What did work ?}
%   \framesubtitle{Combined Model}

%   \begin{figure}
%     \begin{tikzpicture}[x=1.5cm, y=1.5cm, >=stealth, scale = 1]
%       \node [every neuron] (arg) at (0,2.5) {arg};
%       \node [every neuron] (kp) at (0,1.5) {kp};
  
%       \node [layer] (to) at (2.5, 3) {Term overlap};
%       \node [layer] (bb) at (2.5, 1) {BERT + BiLSTM};
  
%       \node [layer] (thr) at (4.5, 3) {?};
  
%       \node [layer] (out) at (7, 3) {out};

%       \draw [->] (arg.45) -- (to.170);
%       \draw [->] (kp.45) -- (to.190);

      
%       \draw [->] (arg.315) -- (bb.170);
%       \draw [->] (kp.315) -- (bb.190);

%       \draw [->] (to) -- (thr);
%       \draw [->] (thr) -- (bb);
%       \draw [->] (thr.0) -- (out);
%       \draw [->] (bb.0) -- (out.190);


%     \end{tikzpicture}
%   \end{figure}
% \end{frame}

% \begin{frame}
%   \frametitle{What does that mean in Scores ?}

%   \begin{figure}
%     \centering
%     \scalebox{.75}{
%       \begin{tabular}{lll}
%         \toprule
%         \multicolumn{1}{c}{\textbf{Approach}} & \multicolumn{1}{c}{\textbf{mAP (str)}} & \multicolumn{1}{c}{\textbf{mAP (rel)}}\\
%         \midrule
%         term overlap (no preprocessing) &	0.52 & 0.70 \\
%         term overlap (stemming) &	0.60 & 0.75\\
%         term overlap (stemming, stop words) & 0.64 & 0.81\\
%         \textbf{term overlap (stemming, stop words, synonyms, antonyms)}	&	\textbf{0.64}	& \textbf{0.82}\\
%         regression (C=1, TF/IDF) & 0.32 & 0.55\\
%         regression (C=14, BOW) & 0.44 & 0.70\\
%         SVC (BOW) & 0.46 & 0.70\\
%         SVC (BOW, POS) & 0.48 & 0.74\\
%         ensemble (LG=0.45, SVC=0.55, BOW) & 0.45 & 0.65\\
%         ensemble (LG=0.45, SVC=0.55, BOW, POS) & 0.51 & 0.71\\
%         BiLSTM (GloVe embeddings) & 0.27 & 0.50\\
%         \bottomrule
%       \end{tabular}
%     }
%   \end{figure}
% \end{frame}

% \begin{frame}
%   \frametitle{Things to do until the deadline}

  

% \end{frame}

\appendix
\section{\appendixname}

\bibliographyframe

\end{document}